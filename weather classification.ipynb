{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65e5d1c2-b39c-4d76-932d-ff19e5fe0333",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f290c472-f7c7-4a00-bb70-e8b65c54b444",
   "metadata": {},
   "source": [
    "#### Loading in our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f9eb2e7-b4ff-4769-bc0e-5e924d078fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('C:/Users/hp/Osasere_data_science/opencv_beginner_2/yolov8-cpu/yolov8s-cls.pt')  # Load the pre-trained YOLOv8 classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86c9d7f-d991-4b11-9a86-ecf68da39bf9",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c39ffed-5ad4-4d56-a58f-6eff49cda273",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.28  Python-3.10.6 torch-2.5.1+cpu CPU (Intel Core(TM) i5-6300U 2.40GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=C:/Users/hp/Osasere_data_science/opencv_beginner_2/yolov8-cpu/yolov8s-cls.pt, data=C:/Users/hp/Osasere_data_science/opencv_beginner_2/yolov8-cpu/weather_classification_project/weather_dataset_splitted, epochs=20, time=None, patience=100, batch=16, imgsz=256, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=None, name=yolov8s_weather7, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\yolov8s_weather7\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\yolov8-cpu\\weather_classification_project\\weather_dataset_splitted\\train... found 1230 images in 6 classes: ERROR  requires 5 classes, not 6\n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\yolov8-cpu\\weather_classification_project\\weather_dataset_splitted\\val... found 173 images in 5 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\yolov8-cpu\\weather_classification_project\\weather_dataset_splitted\\test... found 178 images in 5 classes  \n",
      "Overriding model.yaml nc=1000 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    664325  ultralytics.nn.modules.head.Classify         [512, 5]                      \n",
      "YOLOv8s-cls summary: 99 layers, 5,087,141 parameters, 5,087,141 gradients, 12.6 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\classify\\yolov8s_weather7', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\yolov8-cpu\\weather_classification_project\\weather_da\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\yolov8-cpu\\weather_classification_project\\weather_dataset_splitted\\train\\rainy\\rain141.jpg: ignoring corrupt image/label: Invalid image format GIF. Supported formats are:\n",
      "images: {'jpg', 'bmp', 'mpo', 'png', 'tif', 'pfm', 'heic', 'dng', 'webp', 'tiff', 'jpeg'}\n",
      "videos: {'m4v', 'mov', 'gif', 'mp4', 'mkv', 'asf', 'mpeg', 'ts', 'mpg', 'avi', 'webm', 'wmv'}\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\yolov8-cpu\\weather_classification_project\\weather_dataset_splitted\\train\\shine\\shine126.jpg: corrupt JPEG restored and saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\yolov8-cpu\\weather_classification_project\\weather_dataset_splitted\\train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\yolov8-cpu\\weather_classification_project\\weather_data\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\yolov8-cpu\\weather_classification_project\\weather_dataset_splitted\\val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 256 train, 256 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\yolov8s_weather7\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20         0G      1.223         13        256: 100%|██████████| 77/77 [03:59<00:00,  3.11s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 6/6 [00:11<00:00,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.936          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/20         0G     0.3743         13        256: 100%|██████████| 77/77 [03:56<00:00,  3.07s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 6/6 [00:12<00:00,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.96          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/20         0G     0.1962         13        256: 100%|██████████| 77/77 [03:50<00:00,  2.99s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 6/6 [00:11<00:00,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.96          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/20         0G     0.1575         13        256: 100%|██████████| 77/77 [03:57<00:00,  3.08s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 6/6 [00:12<00:00,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.971          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/20         0G     0.1312         13        256: 100%|██████████| 77/77 [03:55<00:00,  3.05s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 6/6 [00:12<00:00,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.977          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/20         0G     0.1399         13        256: 100%|██████████| 77/77 [03:52<00:00,  3.02s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 6/6 [00:11<00:00,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.977          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/20         0G     0.1415         13        256: 100%|██████████| 77/77 [7:27:56<00:00, 349.05s/it]    \n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 6/6 [00:09<00:00,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.977          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/20         0G     0.1116         13        256: 100%|██████████| 77/77 [1:28:45<00:00, 69.16s/it]     \n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 6/6 [00:07<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.971          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/20         0G    0.08612         13        256: 100%|██████████| 77/77 [02:29<00:00,  1.94s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 6/6 [00:07<00:00,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.971          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/20         0G    0.08919         13        256: 100%|██████████| 77/77 [02:31<00:00,  1.97s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 6/6 [00:07<00:00,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.965          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/20         0G    0.01081         16        256:   1%|▏         | 1/77 [00:04<05:07,  4.04s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC:/Users/hp/Osasere_data_science/opencv_beginner_2/yolov8-cpu/weather_classification_project/weather_dataset_splitted\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Path to the dataset YAML file\u001b[39;49;00m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                    \u001b[49m\u001b[38;5;66;43;03m# Number of epochs\u001b[39;49;00m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                     \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;66;43;03m# Image size(256) used mostly for classication while 640 used for detection\u001b[39;49;00m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                   \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;66;43;03m# Whether to save the best model\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myolov8s_weather\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\yolov8-cpu-env\\lib\\site-packages\\ultralytics\\engine\\model.py:802\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m    801\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[1;32m--> 802\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    803\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\yolov8-cpu-env\\lib\\site-packages\\ultralytics\\engine\\trainer.py:207\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    204\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 207\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\yolov8-cpu-env\\lib\\site-packages\\ultralytics\\engine\\trainer.py:393\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[1;34m(self, world_size)\u001b[0m\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    389\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss \u001b[38;5;241m*\u001b[39m i \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_items) \u001b[38;5;241m/\u001b[39m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_items\n\u001b[0;32m    390\u001b[0m     )\n\u001b[0;32m    392\u001b[0m \u001b[38;5;66;03m# Backward\u001b[39;00m\n\u001b[1;32m--> 393\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;66;03m# Optimize - https://pytorch.org/docs/master/notes/amp_examples.html\u001b[39;00m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ni \u001b[38;5;241m-\u001b[39m last_opt_step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccumulate:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\yolov8-cpu-env\\lib\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\yolov8-cpu-env\\lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\yolov8-cpu-env\\lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    827\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train(\n",
    "    data='C:/Users/hp/Osasere_data_science/opencv_beginner_2/yolov8-cpu/weather_classification_project/weather_dataset_splitted',  # Path to the dataset YAML file\n",
    "    epochs=20,                    # Number of epochs\n",
    "    batch=16,                     \n",
    "    imgsz=256,                 # Image size(256) used mostly for classication while 640 used for detection\n",
    "    device='cpu',                   \n",
    "    save=True,                 # Whether to save the best model\n",
    "    name=\"yolov8s_weather\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e604747-883f-4d3c-a8cd-4df8aa33bfdb",
   "metadata": {},
   "source": [
    "### Making predictions on custom test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c3dd6e2-ecce-457c-bc31-c98e352029f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/27 C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\yolov8-cpu\\weather_classification_project\\weather_test\\Cloud_2.jpg: 256x256 cloudy 1.00, sunrise 0.00, foggy 0.00, shine 0.00, rainy 0.00, 42.9ms\n",
      "image 2/27 C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\yolov8-cpu\\weather_classification_project\\weather_test\\Cloud_4.jpg: 256x256 cloudy 0.77, shine 0.22, sunrise 0.01, foggy 0.00, rainy 0.00, 46.9ms\n",
      "image 3/27 C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\yolov8-cpu\\weather_classification_project\\weather_test\\foggy_1.jpg: 256x256 foggy 0.99, rainy 0.01, cloudy 0.00, shine 0.00, sunrise 0.00, 49.9ms\n",
      "image 4/27 C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\yolov8-cpu\\weather_classification_project\\weather_test\\foggy_10.jpg: 256x256 foggy 0.97, rainy 0.02, cloudy 0.00, shine 0.00, sunrise 0.00, 45.9ms\n",
      "image 5/27 C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\yolov8-cpu\\weather_classification_project\\weather_test\\foggy_2.jpg: 256x256 foggy 1.00, rainy 0.00, shine 0.00, cloudy 0.00, sunrise 0.00, 45.9ms\n",
      "image 6/27 C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\yolov8-cpu\\weather_classification_project\\weather_test\\foggy_3.jpg: 256x256 foggy 1.00, sunrise 0.00, rainy 0.00, shine 0.00, cloudy 0.00, 43.9ms\n",
      "image 7/27 C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\yolov8-cpu\\weather_classification_project\\weather_test\\foggy_4.jpg: 256x256 foggy 1.00, cloudy 0.00, sunrise 0.00, rainy 0.00, shine 0.00, 44.9ms\n",
      "image 8/27 C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\yolov8-cpu\\weather_classification_project\\weather_test\\foggy_5.jpg: 256x256 foggy 1.00, cloudy 0.00, shine 0.00, sunrise 0.00, rainy 0.00, 46.9ms\n",
      "image 9/27 C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\yolov8-cpu\\weather_classification_project\\weather_test\\foggy_6.jpg: 256x256 foggy 1.00, sunrise 0.00, rainy 0.00, cloudy 0.00, shine 0.00, 42.9ms\n",
      "image 10/27 C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\yolov8-cpu\\weather_classification_project\\weather_test\\foggy_7.jpg: 256x256 foggy 1.00, sunrise 0.00, rainy 0.00, shine 0.00, cloudy 0.00, 52.8ms\n",
      "image 11/27 C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\yolov8-cpu\\weather_classification_project\\weather_test\\foggy_8.jpg: 256x256 foggy 1.00, rainy 0.00, shine 0.00, cloudy 0.00, sunrise 0.00, 57.8ms\n",
      "image 12/27 C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\yolov8-cpu\\weather_classification_project\\weather_test\\foggy_9.jpg: 256x256 foggy 0.69, rainy 0.31, cloudy 0.00, shine 0.00, sunrise 0.00, 46.9ms\n",
      "image 13/27 C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\yolov8-cpu\\weather_classification_project\\weather_test\\rain_1.jpg: 256x256 rainy 0.99, cloudy 0.00, shine 0.00, sunrise 0.00, foggy 0.00, 43.9ms\n",
      "image 14/27 C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\yolov8-cpu\\weather_classification_project\\weather_test\\rain_3.jpg: 256x256 rainy 1.00, cloudy 0.00, foggy 0.00, shine 0.00, sunrise 0.00, 41.9ms\n",
      "image 15/27 C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\yolov8-cpu\\weather_classification_project\\weather_test\\rain_4.jpg: 256x256 rainy 1.00, shine 0.00, foggy 0.00, cloudy 0.00, sunrise 0.00, 50.9ms\n",
      "image 16/27 C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\yolov8-cpu\\weather_classification_project\\weather_test\\rain_5.jpg: 256x256 rainy 1.00, foggy 0.00, shine 0.00, cloudy 0.00, sunrise 0.00, 52.9ms\n",
      "image 17/27 C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\yolov8-cpu\\weather_classification_project\\weather_test\\rain_6.jpg: 256x256 rainy 0.99, foggy 0.01, cloudy 0.00, sunrise 0.00, shine 0.00, 53.9ms\n",
      "image 18/27 C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\yolov8-cpu\\weather_classification_project\\weather_test\\shine_1.jpg: 256x256 shine 1.00, sunrise 0.00, rainy 0.00, cloudy 0.00, foggy 0.00, 58.8ms\n",
      "image 19/27 C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\yolov8-cpu\\weather_classification_project\\weather_test\\shine_2.jpg: 256x256 shine 1.00, cloudy 0.00, sunrise 0.00, rainy 0.00, foggy 0.00, 53.9ms\n",
      "image 20/27 C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\yolov8-cpu\\weather_classification_project\\weather_test\\shine_3.jpg: 256x256 shine 0.93, cloudy 0.07, sunrise 0.00, rainy 0.00, foggy 0.00, 55.9ms\n",
      "image 21/27 C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\yolov8-cpu\\weather_classification_project\\weather_test\\sunrise_1.jpg: 256x256 sunrise 1.00, shine 0.00, cloudy 0.00, rainy 0.00, foggy 0.00, 55.9ms\n",
      "image 22/27 C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\yolov8-cpu\\weather_classification_project\\weather_test\\sunrise_2.jpg: 256x256 sunrise 0.99, cloudy 0.00, shine 0.00, foggy 0.00, rainy 0.00, 49.9ms\n",
      "image 23/27 C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\yolov8-cpu\\weather_classification_project\\weather_test\\sunrise_3.jpg: 256x256 sunrise 1.00, shine 0.00, rainy 0.00, cloudy 0.00, foggy 0.00, 53.9ms\n",
      "image 24/27 C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\yolov8-cpu\\weather_classification_project\\weather_test\\sunrise_4.jpg: 256x256 sunrise 1.00, cloudy 0.00, shine 0.00, rainy 0.00, foggy 0.00, 49.9ms\n",
      "image 25/27 C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\yolov8-cpu\\weather_classification_project\\weather_test\\sunrise_5.jpg: 256x256 sunrise 1.00, shine 0.00, cloudy 0.00, rainy 0.00, foggy 0.00, 45.9ms\n",
      "image 26/27 C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\yolov8-cpu\\weather_classification_project\\weather_test\\sunrise_6.jpg: 256x256 sunrise 1.00, shine 0.00, cloudy 0.00, foggy 0.00, rainy 0.00, 49.9ms\n",
      "image 27/27 C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\yolov8-cpu\\weather_classification_project\\weather_test\\sunrise_7.jpg: 256x256 sunrise 1.00, shine 0.00, cloudy 0.00, rainy 0.00, foggy 0.00, 52.3ms\n",
      "Speed: 9.1ms preprocess, 49.5ms inference, 0.1ms postprocess per image at shape (1, 3, 256, 256)\n",
      "Results saved to \u001b[1mruns\\classify\\predict2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Load the model with the latest trained weights\n",
    "model = YOLO('C:/Users/hp/Osasere_data_science/opencv_beginner_2/yolov8-cpu/weather_classification_project/runs/classify/yolov8s_weather7/weights/best.pt')  # Use the path to your best or final weights\n",
    "\n",
    "# Define the path to your test images\n",
    "test_image_path = 'C:/Users/hp/Osasere_data_science/opencv_beginner_2/yolov8-cpu/weather_classification_project/weather_test/*jpg'  # Use wildcard for batch prediction\n",
    "\n",
    "# Run predictions\n",
    "results = model.predict(\n",
    "    source=test_image_path,   # Folder or specific image path\n",
    "    imgsz=640,                # Image size\n",
    "    conf=0.5,                 # Confidence threshold (0-1)\n",
    "    save=True,                # Save predictions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c6eef39-68b7-4770-9708-7a99ee6703fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ultralytics.engine.results.Results object with attributes:\n",
       "\n",
       "boxes: None\n",
       "keypoints: None\n",
       "masks: None\n",
       "names: {0: 'cloudy', 1: 'foggy', 2: 'rainy', 3: 'shine', 4: 'sunrise'}\n",
       "obb: None\n",
       "orig_img: array([[[234, 234, 234],\n",
       "        [235, 235, 235],\n",
       "        [235, 235, 235],\n",
       "        ...,\n",
       "        [ 86,  86,  86],\n",
       "        [ 87,  87,  87],\n",
       "        [ 88,  88,  88]],\n",
       "\n",
       "       [[234, 234, 234],\n",
       "        [233, 233, 233],\n",
       "        [233, 233, 233],\n",
       "        ...,\n",
       "        [ 84,  84,  84],\n",
       "        [ 85,  85,  85],\n",
       "        [ 86,  86,  86]],\n",
       "\n",
       "       [[233, 233, 233],\n",
       "        [232, 232, 232],\n",
       "        [231, 231, 231],\n",
       "        ...,\n",
       "        [ 83,  83,  83],\n",
       "        [ 83,  83,  83],\n",
       "        [ 84,  84,  84]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[156, 156, 156],\n",
       "        [156, 156, 156],\n",
       "        [155, 155, 155],\n",
       "        ...,\n",
       "        [129, 129, 129],\n",
       "        [128, 128, 128],\n",
       "        [128, 128, 128]],\n",
       "\n",
       "       [[155, 155, 155],\n",
       "        [155, 155, 155],\n",
       "        [154, 154, 154],\n",
       "        ...,\n",
       "        [123, 123, 123],\n",
       "        [122, 122, 122],\n",
       "        [121, 121, 121]],\n",
       "\n",
       "       [[155, 155, 155],\n",
       "        [154, 154, 154],\n",
       "        [154, 154, 154],\n",
       "        ...,\n",
       "        [116, 116, 116],\n",
       "        [114, 114, 114],\n",
       "        [112, 112, 112]]], dtype=uint8)\n",
       "orig_shape: (400, 600)\n",
       "path: 'C:\\\\Users\\\\hp\\\\Osasere_data_science\\\\opencv_beginner_2\\\\yolov8-cpu\\\\weather_classification_project\\\\weather_test\\\\Cloud_2.jpg'\n",
       "probs: ultralytics.engine.results.Probs object\n",
       "save_dir: 'runs\\\\classify\\\\predict'\n",
       "speed: {'preprocess': 28.923749923706055, 'inference': 49.866676330566406, 'postprocess': 0.0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b0bc94-09c6-462e-a779-186aa2b84ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedb77dc-edd7-45c3-8ae7-21aee0a9feec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d862d0-e243-46e4-80cd-a03b650e1076",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5220158-d9dc-4762-be09-115477a7424f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee823c06-b2a9-488e-b416-4c7a5ea60099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaea7a9-d846-4322-86d1-1d3de38e667f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8808dd1e-8202-4a10-b855-daf65345056e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e729744e-ef02-463c-84cd-feb8898da5b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c668d11-714d-4fca-b6b7-7bc12efd70d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (yolov8-cpu-env)",
   "language": "python",
   "name": "yolov8-cpu-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
